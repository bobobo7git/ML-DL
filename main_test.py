from fastapi import FastAPI, Request
from fastapi.middleware.cors import CORSMiddleware
import httpx
import json
import faiss
import numpy as np
from sentence_transformers import SentenceTransformer
from typing import Dict
import re
# âœ… ëŒ€í™” ë©”ëª¨ë¦¬ ì´ˆê¸°í™”
chat_memory: Dict[str, list[str]] = {}
print("ğŸš¨ [chat_memory] ìƒë‹´ ëŒ€í™” ê¸°ë¡ ì´ˆê¸°í™” ì™„ë£Œ â€“ ìƒˆë¡œìš´ ì„¸ì…˜ìœ¼ë¡œ ì‹œì‘í•©ë‹ˆë‹¤.")
app = FastAPI()

# === CORS ì„¤ì • ===
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# === ëª¨ë¸, ë°ì´í„° ë¡œë”© ===
OLLAMA_URL = "http://localhost:11434/api/generate"
MODEL_NAME = "gemma3:12b-it-qat"

retriever_model = SentenceTransformer("BAAI/bge-m3")
index = faiss.read_index("qa_index_bge_m3.faiss")
with open("qa_chunks.json", "r", encoding="utf-8") as f:
    chunks = json.load(f)

chat_memory: Dict[str, list[str]] = {}

# === ìœ ì‚¬ë¬¸ì„œ ê²€ìƒ‰ ===
def retrieve_relevant_chunks(query: str, top_k: int = 3) -> list[str]:
    query_vec = retriever_model.encode([f"ì§ˆë¬¸: {query}"], convert_to_numpy=True)
    faiss.normalize_L2(query_vec)
    _, I = index.search(query_vec, top_k)
    return [chunks[i] for i in I[0]]

# === í”„ë¡¬í”„íŠ¸ ìƒì„± ===
def build_rag_prompt(
    query: str,
    retrieved_docs: list[str],
    history_text: str,
    nickname: str,
    user_context: dict,
    emotion: dict
) -> str:
    context = "\n\n".join(retrieved_docs)

    profile_info = []
    if user_context.get("age"):
        profile_info.append(f"{user_context['age']} ì—°ë ¹ëŒ€")
    if user_context.get("gender"):
        profile_info.append(f"{user_context['gender']} ì„±ë³„")
    if user_context.get("career"):
        profile_info.append(f"{user_context['career']} ì§ì—…")
    if user_context.get("mbti"):
        profile_info.append(f"{user_context['mbti']} ì„±ê²©ìœ í˜•")
    if user_context.get("stressReason"):
        profile_info.append(f"ìŠ¤íŠ¸ë ˆìŠ¤ ìš”ì¸: {user_context['stressReason']}")

    profile_summary = ", ".join(profile_info)
    emotion_summary = (
        f"ê°ì • ë¶„ì„ ê²°ê³¼: "
        f"ìš°ìš¸({emotion.get('sadness', 0)}), í–‰ë³µ({emotion.get('happiness', 0)}), "
        f"ë¶„ë…¸({emotion.get('angry', 0)}), ì¤‘ë¦½({emotion.get('neutral', 0)}), ê¸°íƒ€({emotion.get('other', 0)})"
    )

    return f"""
ë„ˆëŠ” ë”°ëœ»í•˜ê³  ì‹ ë¢°ê° ìˆëŠ” AI ì‹¬ë¦¬ìƒë‹´ì‚¬ì•¼.
ë§íˆ¬ëŠ” {user_context.get("botCustom", "ìƒëƒ¥í•œ")} í†¤ìœ¼ë¡œ ìœ ì§€í•´.

ìƒë‹´ìëŠ” "{nickname}"ì´ë¼ëŠ” ì´ë¦„ìœ¼ë¡œ ë¶ˆë¦¬ê³  ì‹¶ì–´ í•´. ë°˜ë“œì‹œ ì´ ì´ë¦„ì„ ì‚¬ìš©í•´ì„œ ë§í•´ì¤˜.

ìƒë‹´ìì˜ ë°°ê²½ ì •ë³´: {profile_summary}
{emotion_summary}

ì§€ê¸ˆê¹Œì§€ ìƒë‹´ìì™€ ë‚˜ëˆˆ ëŒ€í™” ê¸°ë¡ì€ ë‹¤ìŒê³¼ ê°™ì•„:

{history_text}

[ìƒë‹´ì ì§ˆë¬¸]
{query}

[AI ìƒë‹´ì‚¬ì˜ ë‹µë³€ ì§€ì¹¨]
- ë°˜ë“œì‹œ ì‚¬ìš©ìê°€ â€œì•ˆë…•â€, â€œì•ˆë…•í•˜ì„¸ìš”â€, â€œhiâ€ ë“± ëª…ì‹œì ì¸ ì¸ì‚¬ë¥¼ í–ˆì„ ê²½ìš°ì—ë§Œ ê°€ë³ê²Œ ì¸ì‚¬í•´.
- **ì¸ì‚¬ ì´í›„ì—ë„**, ë‚´ë‹´ìê°€ ë§í•˜ì§€ ì•Šì€ ê°ì •, ë°°ê²½, ê³¼ê±° ì‚¬ê±´ ë“±ì€ ì ˆëŒ€ ìœ ì¶”í•˜ì§€ ë§ˆ.
- íŠ¹íˆ, ì¸ì‚¬ì— ì´ì–´ â€œìš”ì¦˜ í˜ë“œì…¨ì£ ?â€, â€œíšŒì‚¬ ì¼ì´ í˜ë“œì…¨ì£ ?â€, â€œê¿ˆì„ ìŠìœ¼ì…¨ì£ ?â€ ë“±ì˜ í‘œí˜„ì€ **ê¸ˆì§€ì•¼.**
- ì¸ì‚¬ ì´í›„ì—ëŠ” ë°˜ë“œì‹œ â€œë¬´ì—‡ì´ ê°€ì¥ ë§ˆìŒì— ê±¸ë¦¬ì…¨ì„ê¹Œìš”?â€, â€œì–´ë–¤ ì´ì•¼ê¸°ë¶€í„° ë‚˜ëˆ ë³¼ê¹Œìš”?â€ì²˜ëŸ¼ **ì¤‘ë¦½ì ì¸ ì§ˆë¬¸ìœ¼ë¡œ ì—°ê²°í•´.**

âŒ ì˜ˆì‹œ (ì˜ëª»ëœ ì‘ë‹µ):
ì§ˆë¬¸: ì•ˆë…•í•˜ì„¸ìš”  
ì‘ë‹µ: ì•ˆë…•í•˜ì„¸ìš”, ë‚´ë‹´ì´ë‹˜. ìš”ì¦˜ ë§ì´ í˜ë“œì…¨ì£ ? íšŒì‚¬ë„ ê·¸ë ‡ê³ ...

âœ… ì˜ˆì‹œ (ì¢‹ì€ ì‘ë‹µ):
ì§ˆë¬¸: ì•ˆë…•í•˜ì„¸ìš”  
ì‘ë‹µ: ì•ˆë…•í•˜ì„¸ìš”, {nickname}ë‹˜. ë°˜ê°‘ìŠµë‹ˆë‹¤. ì–´ë–¤ ì´ì•¼ê¸°ë¶€í„° ë‚˜ëˆ ë³¼ê¹Œìš”?

- ì‚¬ìš©ìê°€ ë§í•˜ì§€ ì•Šì€ ë‚´ìš©(íšŒì‚¬, íŒ€ì›, ì§‘, ê¿ˆ, ìš°ìš¸í•¨ ë“±)ì€ ì ˆëŒ€ ë§í•˜ì§€ ë§ˆ.

- ì •ë³´ê°€ ë¶€ì¡±í•  ê²½ìš° ì¶”ì¸¡í•˜ì§€ ë§ê³ , ìƒí™©ì— ë§ëŠ” ê°„ë‹¨í•œ ì§ˆë¬¸ì„ ì œì‹œí•´.

- ë‚´ë‹´ìì˜ ê°ì • ìƒíƒœëŠ” ë°˜ë“œì‹œ **ë°œí™”ì— ë‚˜íƒ€ë‚œ ì§ì ‘ì  í‘œí˜„**ì— ê¸°ë°˜í•˜ì—¬ ì¶”ì¸¡í•´.  
  ì˜ˆ: â€œë„ˆë¬´ í˜ë“¤ë‹¤â€ë¼ê³  í–ˆë‹¤ë©´ â†’ â€œê·¸ë§Œí¼ í˜ë“  ì‹œê°„ì´ì…¨ë˜ ê²ƒ ê°™ì•„ìš”â€ì™€ ê°™ì´ ë°˜ì˜í•˜ë˜, **ë°°ê²½ ìœ ì¶” ê¸ˆì§€.**

- ì‚¬ìš©ìê°€ ë³¸ì¸ì´ í–ˆë˜ ì§ˆë¬¸ì„ ê¸°ì–µí•˜ëƒê³  ë¬¼ì–´ë³´ë©´, ë°˜ë“œì‹œ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì´ ë¬´ì—‡ì´ì—ˆëŠ”ì§€ ê¸°ì–µí•´ì„œ ì•Œë ¤ì¤˜. ë‹¤ë¥¸ ë§ì„ í•˜ì§€ë§ˆ.
  ì˜ˆ: "ë°©ê¸ˆ ì „ì— ì €ì—ê²Œ ìš”ì¦˜ ë„ˆë¬´ í˜ë“¤ë‹¤ê³  ë§ì”€í•´ì£¼ì…¨ì–´ìš”."

- ì ˆëŒ€ ë§í•˜ì§€ ì•Šì€ ë°°ê²½, ì¥ì†Œ, ê´€ê³„(ì˜ˆ: í•™êµ, ì§‘, ê°€ì¡±, ì¹œêµ¬, ì§ì¥ ë“±)ë¥¼ **ì¶”ë¡ í•˜ê±°ë‚˜ ì–¸ê¸‰í•˜ì§€ ë§ˆ.**  
  âŒ â€œí•™êµì™€ ì§‘ì•ˆ ëª¨ë‘ì—ì„œ ì–´ë ¤ì›€ì„ ê²ªê³  ê³„ì‹œê³ ...â€ â† ì´ëŸ° ë¬¸ì¥ì€ ê¸ˆì§€

- ë‚´ë‹´ìê°€ ìš”ì²­í•˜ì§€ ì•Šì€ **í•´ê²°ì±…ì´ë‚˜ ì¡°ì–¸ì„ ì œì‹œí•˜ì§€ ë§ˆ.**  
  ì˜ˆ: â€œì¼ê¸°ë¥¼ ì¨ë³´ì„¸ìš”â€, â€œì „ë¬¸ê°€ì™€ ì´ì•¼ê¸°í•´ë³´ì„¸ìš”â€ ë“±ì€ ë§í•˜ì§€ ë§ˆ

- ìœ„ë¡œ í‘œí˜„ë„ **í•œë‘ ë¬¸ì¥ ì´ìƒ ë°˜ë³µí•˜ì§€ ë§ˆ.**  
  ì˜ˆ: â€œí˜¼ìê°€ ì•„ë‹ˆì—ìš”â€, â€œê³ì— ìˆì–´ìš”â€ ê°™ì€ ë¬¸ì¥ì€ ìµœëŒ€ 1íšŒ ì´í•˜ë¡œë§Œ í‘œí˜„í•˜ê³ , **ì¤‘ë³µëœ í‘œí˜„ì€ í”¼í•´ì•¼ í•¨**

- ì•„ë˜ ì°¸ê³  ë¬¸ì„œì˜ ë‹µë³€ ìŠ¤íƒ€ì¼(A)ì„ ì°¸ê³ í•´. ë‹¤ë§Œ, **ì‚¬ìš©ìì˜ ì…ë ¥ì´ ìš°ì„ ì´ë©°, ì°¸ê³  ë¬¸ì„œì— ìˆëŠ” ê°ì •ì´ë‚˜ ì‚¬ê±´ì„ ëŒì–´ì˜¤ì§€ ë§ˆ.**

- ë°˜ë“œì‹œ '{nickname}ë‹˜'ì´ë¼ê³  ë¶€ë¥´ê³ , ì‘ë‹µì€ 3~5ë¬¸ì¥, í•˜ë‚˜ì˜ ë¬¸ë‹¨ìœ¼ë¡œ ê°„ê²°í•˜ê²Œ ë§ˆë¬´ë¦¬í•´.  
  ë¬¸ì¥ì´ ë„ˆë¬´ ê¸¸ê±°ë‚˜ ë‹¨ë½ì´ ì—¬ëŸ¬ ê°œì¸ ë‹µë³€ì€ ë¶ˆì•ˆê°ì„ ì¤„ ìˆ˜ ìˆìœ¼ë‹ˆ ì§€ì–‘í•´.

[â— ì˜ˆì‹œ]

ì§ˆë¬¸: ë‚˜ ë„ˆë¬´ í˜ë“¤ë‹¤!!!  
ì˜ëª»ëœ ì‘ë‹µ âŒ: í•™êµì™€ ì§‘ì•ˆì—ì„œë„ ì–´ë ¤ì›€ì„ ê²ªê³  ê³„ì‹œê³ ...  
ì˜ëœ ì‘ë‹µ âœ…: ê·¸ë ‡ê²Œ ë§ì”€í•˜ì‹  ê±¸ ë³´ë‹ˆ ì •ë§ ì§€ì¹˜ì…¨ë˜ ê²ƒ ê°™ì•„ìš”. ì–´ë–¤ ë¶€ë¶„ì´ ê°€ì¥ í˜ë“¤ê²Œ ëŠê»´ì¡Œì„ê¹Œìš”?

â†’ ë°˜ë“œì‹œ â€œì‚¬ìš©ìì˜ ì…ë ¥ ë²”ìœ„ ë‚´ì—ì„œë§Œâ€ ì‘ë‹µì„ ìƒì„±í•˜ê³ , ê·¸ ì™¸ì˜ í•´ì„ì€ í•˜ì§€ ë§ˆ.


[â— ì ˆëŒ€ ê¸ˆì§€ ì‚¬í•­ ì˜ˆì‹œ]
âŒ ì‚¬ìš©ìê°€ ë§í•˜ì§€ ì•Šì€ í™˜ê²½(ì˜ˆ: ì§‘ì•ˆ, ë¶€ëª¨) ìœ ì¶”  
âŒ ì •í•´ì§„ ë“¯í•œ ì¡°ì–¸ ("ì‘ì€ ê²ƒë¶€í„° ì‹œì‘í•´ë³´ì„¸ìš”" ë“± ë°˜ë³µ ë¬¸êµ¬)  
âœ… ì‚¬ìš©ìì˜ í‘œí˜„ì„ ìˆëŠ” ê·¸ëŒ€ë¡œ ë°˜ì˜ ("ë„ˆë¬´ í˜ë“¤ë‹¤" â†’ "ê·¸ë ‡ê²Œ ë§ì”€í•˜ì‹  ê±¸ ë³´ë‹ˆ ì •ë§ ì§€ì¹˜ì…¨ë˜ ê²ƒ ê°™ì•„ìš”")

[ì°¸ê³  ë¬¸ì„œ]
ì•„ë˜ëŠ” ìœ ì‚¬í•œ ìƒë‹´ ë¬¸ì„œì—ì„œ ë°œì·Œí•œ ì‹¤ì œ ì‘ë‹µ ì˜ˆì‹œì•¼.  
â†’ ë‹¨, í‘œí˜„ ë°©ì‹ë§Œ ì°¸ê³ í•˜ê³ , ì—¬ê¸°ì— ìˆëŠ” ë‚´ìš©(ì¥ì†Œ, ì¸ë¬¼, ì‚¬ê±´ ë“±)ì€ ì ˆëŒ€ ê°€ì ¸ì˜¤ì§€ ë§ˆ.

{context}
"""

# === /ai-data/chat ì—”ë“œí¬ì¸íŠ¸ ===


@app.post("/chat")
async def chat(request: Request):
    
    body = await request.json()
    nickname = body.get("nickname", "ìƒë‹´ìë‹˜")
    message = body.get("message", "")
    user_context = body.get("userContext", {}) or {}
    emotion = body.get("emotion", {}) or {}
    print("í˜„ì¬ ëŒ€í™” ì´ë ¥:", chat_memory.get(nickname))
    if nickname not in chat_memory:
        chat_memory[nickname] = []


    # ëŒ€í™” ê¸°ë¡ ì—…ë°ì´íŠ¸
    chat_memory[nickname].append(f"{nickname}: {message}")
    history_text = "\n".join(chat_memory[nickname][-6:])
    retrieved_docs = retrieve_relevant_chunks(message)

    # í”„ë¡¬í”„íŠ¸ ìƒì„±
    prompt = build_rag_prompt(
        query=message,
        retrieved_docs=retrieved_docs,
        history_text=history_text,
        nickname=nickname,
        user_context=user_context,
        emotion=emotion
    )

    payload = {
        "model": MODEL_NAME,
        "prompt": prompt,
        "stream": False,
        "num_predict": 250,
        "top_k": 40,
        "top_p": 0.9,
        "temperature": 0.7
    }

    try:
        async with httpx.AsyncClient(timeout=120.0) as client:
            res = await client.post(OLLAMA_URL, json=payload)
            result = res.json()
            ai_text = result.get("response", "").strip()
    except Exception as e:
        print("[âŒ chat ì˜ˆì™¸ ë°œìƒ]", str(e))
        return {"ai_response": "ëª¨ë¸ ì‘ë‹µ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."}

    chat_memory[nickname].append(f"AI: {ai_text}")
    return {"ai_response": ai_text}


# ğŸ“‹ ìš”ì•½ í”„ë¡¬í”„íŠ¸
def build_summary_prompt(history_text: str) -> str:
    return f"""
ë„ˆëŠ” ì§€ê¸ˆê¹Œì§€ì˜ ìƒë‹´ ëŒ€í™”ë¥¼ ë°”íƒ•ìœ¼ë¡œ ìƒë‹´ìë‹˜ì˜ ê°ì • ìƒíƒœë¥¼ ë¶„ì„í•˜ëŠ” ì‹¬ë¦¬ìƒë‹´ì‚¬ì•¼.
Russell ê°ì • ì›í˜• ëª¨í˜•(Circumplex Model of Affect)ì— ë”°ë¼ ê°ì •ì„ ë¶„ì„í•´.

ì•„ë˜ëŠ” ìƒë‹´ìì™€ AIì˜ ì „ì²´ ëŒ€í™” ë‚´ìš©ì´ì•¼:

{history_text}

ì´ ìƒë‹´ ë‚´ìš©ì„ ê¸°ë°˜ìœ¼ë¡œ, ì•„ë˜ JSON í˜•ì‹ìœ¼ë¡œ ìš”ì•½ ë³´ê³ ì„œë¥¼ ì‘ì„±í•´ì¤˜.
ì´ ìƒë‹´ ë‚´ìš©ì„ ê¸°ë°˜ìœ¼ë¡œ ì•„ë˜ í˜•ì‹ì— ë§ëŠ” JSON ë¦¬í¬íŠ¸ë¥¼ ì‘ì„±í•´ì¤˜. ê° í•„ë“œëŠ” ë‹¤ìŒì„ ì¶©ì‹¤íˆ ë°˜ì˜í•´ì•¼ í•´:

---

ğŸ“Œ "summary": ì „ì²´ ìƒë‹´ ë‚´ìš©ì„ ê°ê´€ì ìœ¼ë¡œ ìš”ì•½í•´. ê°ì • ë¶„ì„ì€ í•˜ì§€ ë§ê³ , ì–´ë–¤ ì£¼ì œë¡œ ì–´ë–¤ ì´ì•¼ê¸°ë“¤ì´ ì˜¤ê°”ëŠ”ì§€ë§Œ ê°„ê²°í•˜ê²Œ ì •ë¦¬í•´.

ğŸ“Œ "analyze": ëŒ€í™” ì¤‘ ìƒë‹´ìì˜ ê°ì •ì´ ì–´ë–»ê²Œ í˜ëŸ¬ê°”ëŠ”ì§€ ë¶„ì„í•´ì¤˜. ì˜ˆë¥¼ ë“¤ì–´, ì²˜ìŒì—ëŠ” ë¶ˆì•ˆí–ˆì§€ë§Œ ì ì°¨ ì•ˆì •ì„ ì°¾ì•˜ë‹¤ê±°ë‚˜, ë¶„ë…¸ê°€ ì ì  ì¤„ì–´ë“¤ê³  ë¬´ê¸°ë ¥í•¨ì´ ë“œëŸ¬ë‚¬ë‹¤ëŠ” ì‹ìœ¼ë¡œ ì‹œê°„ ìˆœì„œì˜ ê°ì • ë³€í™”ë¥¼ ì„œìˆ í•´.

ğŸ“Œ "valence": Russell ê°ì • ì›í˜• ëª¨ë¸ ê¸°ì¤€ìœ¼ë¡œ ìƒë‹´ìì˜ ì „ë°˜ì ì¸ ê°ì • ë°©í–¥ì„ í‰ê°€í•´. (ì˜ˆ: "positive", "neutral", "negative")

ğŸ“Œ "arousal": Russell ê°ì • ì›í˜• ëª¨ë¸ ê¸°ì¤€ìœ¼ë¡œ ê°ì •ì˜ í™œì„±ë„ë¥¼ í‰ê°€í•´. (ì˜ˆ: "high", "medium", "low")

---

âœ… ë°˜ë“œì‹œ ì•„ë˜ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì¶œë ¥í•˜ê³ , ì„¤ëª… ë¬¸ì¥ì´ë‚˜ ì—¬ë¶„ì˜ í…ìŠ¤íŠ¸ëŠ” ì ˆëŒ€ í¬í•¨í•˜ì§€ ë§ˆ.  
âœ… JSON í‚¤ ì´ë¦„ì€ ë°˜ë“œì‹œ ì˜ë¬¸ ì†Œë¬¸ìë¡œ ìœ ì§€í•˜ê³ , ìˆœì„œë„ ìœ ì§€í•´.

```json
{{
  "summary": "ëŒ€í™” ìš”ì•½ (ì˜ˆ: ìƒë‹´ìëŠ” ìµœê·¼ ì—…ë¬´ ìŠ¤íŠ¸ë ˆìŠ¤ë¡œ ì¸í•´ ë¶ˆë©´ì„ ê²ªê³  ìˆìŒì„ ì´ì•¼ê¸°í–ˆë‹¤...)",
  "analyze": "ê°ì • ë³€í™” ë¶„ì„ (ì˜ˆ: ì´ˆë°˜ì—ëŠ” ë¶„ë…¸ê°€ ìˆì—ˆì§€ë§Œ ì ì  ìš°ìš¸ê³¼ ë¬´ê¸°ë ¥í•¨ì´ ê°•ì¡°ë˜ì—ˆë‹¤...)",
  "valence": "positive | neutral | negative",
  "arousal": "high | medium | low"
}}
```
"""

@app.post("/summary")
async def summarize(request: Request):
    body = await request.json()
    nickname = body.get("nickname", "default")

    if nickname not in chat_memory or not chat_memory[nickname]:
        return {"summary": "ìš”ì•½í•  ìƒë‹´ ê¸°ë¡ì´ ì—†ìŠµë‹ˆë‹¤."}

    history_text = "\n".join(chat_memory[nickname])
    prompt = build_summary_prompt(history_text)

    payload = {
        "model": MODEL_NAME,
        "prompt": prompt,
        "stream": False,
        "num_predict": 400,
        "top_k": 40,
        "top_p": 0.9,
        "temperature": 0.7
    }

    try:
        async with httpx.AsyncClient(timeout=120.0) as client:
            res = await client.post(OLLAMA_URL, json=payload)
            result = res.json()
            response_text = result.get("response", "").strip()

            try:
                return json.loads(response_text)
            except json.JSONDecodeError:
                match = re.search(r"\{[\s\S]*\}", response_text)
                if match:
                    return json.loads(match.group())
                else:
                    return {
                        "summary": "JSON í˜•ì‹ì„ íŒŒì‹±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.",
                        "raw_response": response_text
                    }

    except Exception as e:
        print("[âŒ ìš”ì•½ ì˜¤ë¥˜ ë°œìƒ]", str(e))
        return {
            "summary": "ë ˆí¬íŠ¸ë¥¼ ìƒì„±í•˜ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.",
            "raw_response": response_text if "response_text" in locals() else "ì—†ìŒ"
        }

