{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "31978cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "label2id = {'Happy': 0, 'Sad': 1, 'Angry': 2, 'Anxious': 3, 'Hurt': 4, 'Embarrassed': 5, 'Neutrality': 6}\n",
    "id2label = {0: 'Happy', 1: 'Sad', 2: 'Angry', 3: 'Anxious', 4: 'Hurt', 5: 'Embarrassed', 6: 'Neutrality'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "26a790b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "\n",
    "def find_wav_files(base_dir, is_train:bool, per_class=100):\n",
    "    sub_root = '1.Training' if is_train else '2.Validation'\n",
    "    \n",
    "    wav_files = []\n",
    "    folder2label = {\n",
    "        '1.기쁨': 'Happy',\n",
    "        '2.슬픔': 'Sad', \n",
    "        '3.분노': 'Angry', \n",
    "        '4.불안': 'Anxious', \n",
    "        '5.상처': 'Hurt',\n",
    "        '6.당황': 'Embarrassed', \n",
    "        '7.중립': 'Neutrality'\n",
    "    }\n",
    "    emotion_dir = os.path.join(\n",
    "        base_dir, \n",
    "        '01.데이터', \n",
    "        sub_root,\n",
    "        '원천데이터',\n",
    "        ('T' if is_train else 'V') + 'S1',\n",
    "        ('T' if is_train else 'V') + 'S1',\n",
    "        '1.감정'\n",
    "    )\n",
    "    wav_path_dict = {label: [] for label in folder2label.keys()}\n",
    "\n",
    "    for emo in os.listdir(emotion_dir):\n",
    "        emo_path = os.path.join(emotion_dir, emo)\n",
    "\n",
    "        wav_per_class = []\n",
    "        if not os.path.isdir(emo_path): continue\n",
    "        for sub_folder in os.listdir(emo_path):\n",
    "            sub_emo_path = os.path.join(emo_path, sub_folder)\n",
    "            if not os.path.isdir(sub_emo_path): continue\n",
    "\n",
    "            wav_list = [\n",
    "                os.path.join(sub_emo_path, f)\n",
    "                for f in os.listdir(sub_emo_path) if f.endswith('.wav')\n",
    "            ]\n",
    "            if len(wav_list) == 0:\n",
    "                continue\n",
    "            \n",
    "            # sampled = random.sample(wav_list, min(per_class, len(wav_list)))\n",
    "            # wav_files.extend(sampled)\n",
    "            # wav_files.extend(wav_list)\n",
    "            wav_per_class.extend(wav_list)\n",
    "        wav_path_dict[emo].extend(wav_per_class)\n",
    "    return wav_path_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "be6f5153",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DIR = r'C:\\Users\\SSAFY\\Downloads\\015.감성 및 발화 스타일별 음성합성 데이터'\n",
    "wav_path_dict = find_wav_files(BASE_DIR, is_train=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f46e0a49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.기쁨: C:\\Users\\SSAFY\\Downloads\\015.감성 및 발화 스타일별 음성합성 데이터\\01.데이터\\1.Training\\원천데이터\\TS1\\TS1\\1.감정\\1.기쁨\\0001_G1A3E1S0C0_PSB\\0001_G1A3E1S0C0_PSB_000001.wav\n",
      "66097\n",
      "2.슬픔: C:\\Users\\SSAFY\\Downloads\\015.감성 및 발화 스타일별 음성합성 데이터\\01.데이터\\1.Training\\원천데이터\\TS1\\TS1\\1.감정\\2.슬픔\\0001_G1A3E2S0C0_PSB\\0001_0001_G1A3E2S0C0_PSB_000001.wav\n",
      "64359\n",
      "3.분노: C:\\Users\\SSAFY\\Downloads\\015.감성 및 발화 스타일별 음성합성 데이터\\01.데이터\\1.Training\\원천데이터\\TS1\\TS1\\1.감정\\3.분노\\0001_G1A3E3S0C0_PSB\\0001_G1A3E3S0C0_PSB_000001.wav\n",
      "65715\n",
      "4.불안: C:\\Users\\SSAFY\\Downloads\\015.감성 및 발화 스타일별 음성합성 데이터\\01.데이터\\1.Training\\원천데이터\\TS1\\TS1\\1.감정\\4.불안\\0001_G1A3E4S0C0_PSB\\0001_G1A3E4S0C0_PSB_000001.wav\n",
      "65853\n",
      "5.상처: C:\\Users\\SSAFY\\Downloads\\015.감성 및 발화 스타일별 음성합성 데이터\\01.데이터\\1.Training\\원천데이터\\TS1\\TS1\\1.감정\\5.상처\\0002_G1A4E5S0C0_LYT\\0002_G1A4E5S0C0_LYT_000001.wav\n",
      "63740\n",
      "6.당황: C:\\Users\\SSAFY\\Downloads\\015.감성 및 발화 스타일별 음성합성 데이터\\01.데이터\\1.Training\\원천데이터\\TS1\\TS1\\1.감정\\6.당황\\0002_G1A4E6S0C0_LYT\\0002_G1A4E6S0C0_LYT_000001.wav\n",
      "64160\n",
      "7.중립: C:\\Users\\SSAFY\\Downloads\\015.감성 및 발화 스타일별 음성합성 데이터\\01.데이터\\1.Training\\원천데이터\\TS1\\TS1\\1.감정\\7.중립\\0002_G1A4E7S0C0_LYT\\0002_G1A4E7S0C0_LYT_000001.wav\n",
      "64000\n"
     ]
    }
   ],
   "source": [
    "for emo in wav_path_dict:\n",
    "    print(f'{emo}: {wav_path_dict[emo][0]}')\n",
    "    print(len(wav_path_dict[emo]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "90c65702",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "\n",
    "def extract_mfcc(file_path, n_mfcc=20):\n",
    "    y, sr = librosa.load(file_path, sr=16000)\n",
    "    mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=n_mfcc)  # shape: (n_mfcc, frame)\n",
    "    return mfcc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e477d52e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "mfcc_list_dict = {emo: dict() for emo in label2id.keys()}\n",
    "\n",
    "def get_top_features(wav_path_dict: dict, top_k=10):\n",
    "    mfcc_mean_dict = {emo:0 for emo in wav_path_dict.keys()}\n",
    "    for emo, path_list in wav_path_dict.items():\n",
    "        mfcc_means = []\n",
    "        for path in tqdm(path_list, desc=f'{emo}: '):\n",
    "            mfcc = extract_mfcc(path, n_mfcc=20)\n",
    "            mfcc_list_dict[emo][path] = mfcc\n",
    "            mfcc_mean = np.mean(mfcc, axis=1)\n",
    "            mfcc_means.append(mfcc_mean)\n",
    "        mfcc_mean_dict[emo] = np.mean(mfcc_means, axis=0)\n",
    "    all_emotion_means = np.stack(list(mfcc_mean_dict.values()))\n",
    "    global_mean = np.mean(all_emotion_means, axis=0)\n",
    "\n",
    "    top_indices = np.argsort(global_mean)[::-1][:top_k]\n",
    "    return top_indices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4c3e3c3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1.기쁨: 100%|██████████| 66097/66097 [15:37<00:00, 70.51it/s]\n",
      "2.슬픔: 100%|██████████| 64359/64359 [15:19<00:00, 69.99it/s]\n",
      "3.분노: 100%|██████████| 65715/65715 [15:26<00:00, 70.89it/s]\n",
      "4.불안: 100%|██████████| 65853/65853 [16:47<00:00, 65.35it/s]\n",
      "5.상처: 100%|██████████| 63740/63740 [17:29<00:00, 60.75it/s]\n",
      "6.당황: 100%|██████████| 64160/64160 [16:50<00:00, 63.48it/s]\n",
      "7.중립: 100%|██████████| 64000/64000 [15:56<00:00, 66.91it/s]\n"
     ]
    }
   ],
   "source": [
    "top_indices = get_top_features(wav_path_dict=wav_path_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "ba59909a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1,  3,  5,  2,  6, 13, 11, 15, 17, 19])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4715152",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "\n",
    "y, sr = librosa.load('sample.wav', sr=16000)\n",
    "mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=20) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
